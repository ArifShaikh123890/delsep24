{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--driver-class-path /usr/local/sqoop/lib/mysql-connector-java-5.1.47-bin.jar \\\n",
    "--jars /usr/local/sqoop/lib/mysql-connector-java-5.1.47/mysql-connector-java-5.1.47-bin.jar pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                    .appName('MySQL RW').master('local[*]')\\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+-------+-------+------+\n",
      "|empno|ename |job      |mgr |hiredate  |sal    |comm   |deptno|\n",
      "+-----+------+---------+----+----------+-------+-------+------+\n",
      "|7369 |SMITH |CLERK    |7902|1980-12-17|800.00 |null   |20    |\n",
      "|7499 |ALLEN |SALESMAN |7698|1981-02-20|1600.00|300.00 |30    |\n",
      "|7521 |WARD  |SALESMAN |7698|1981-02-22|1250.00|500.00 |30    |\n",
      "|7566 |JONES |MANAGER  |7839|1981-04-02|2975.00|null   |20    |\n",
      "|7654 |MARTIN|SALESMAN |7698|1981-09-28|1250.00|1400.00|30    |\n",
      "|7698 |BLAKE |MANAGER  |7839|1981-05-01|2850.00|null   |30    |\n",
      "|7782 |CLARK |MANAGER  |7839|1981-06-09|2450.00|null   |10    |\n",
      "|7788 |SCOTT |ANALYST  |7566|1982-12-09|3000.00|null   |20    |\n",
      "|7839 |KING  |PRESIDENT|null|1981-11-17|5000.00|null   |10    |\n",
      "|7844 |TURNER|SALESMAN |7698|1981-09-08|1500.00|0.00   |30    |\n",
      "|7876 |ADAMS |CLERK    |7788|1983-01-12|1100.00|null   |20    |\n",
      "|7900 |JAMES |CLERK    |7698|1981-12-03|950.00 |null   |30    |\n",
      "|7902 |FORD  |ANALYST  |7566|1981-12-03|3000.00|null   |20    |\n",
      "|7934 |MILLER|CLERK    |7782|1982-01-23|1300.00|null   |10    |\n",
      "+-----+------+---------+----+----------+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf = spark.read.format('jdbc')\\\n",
    "            .option('url','jdbc:mysql://localhost:3306/saif_db?useSSL=False')\\\n",
    "            .option('driver','com.mysql.jdbc.Driver')\\\n",
    "            .option('user','root')\\\n",
    "            .option('password','root')\\\n",
    "            .option('dbtable','emp')\\\n",
    "            .load()\n",
    "empDf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+----+----------+-------+----+------+\n",
      "|empno|ename|      job| mgr|  hiredate|    sal|comm|deptno|\n",
      "+-----+-----+---------+----+----------+-------+----+------+\n",
      "| 7369|SMITH|    CLERK|7902|1980-12-17| 800.00|null|    20|\n",
      "| 7566|JONES|  MANAGER|7839|1981-04-02|2975.00|null|    20|\n",
      "| 7782|CLARK|  MANAGER|7839|1981-06-09|2450.00|null|    10|\n",
      "| 7788|SCOTT|  ANALYST|7566|1982-12-09|3000.00|null|    20|\n",
      "| 7839| KING|PRESIDENT|null|1981-11-17|5000.00|null|    10|\n",
      "+-----+-----+---------+----+----------+-------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark SQL:\n",
    "# We need to convert DF to Temp Table:\n",
    "\n",
    "empDf.createOrReplaceTempView('emp')\n",
    "spark.sql('select * from emp where deptno in (10,20)').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+------------+\n",
      "|emp_empno|emp_ename|mgr_empno|mgr_ename|mgr_team_cnt|\n",
      "+---------+---------+---------+---------+------------+\n",
      "|     7902|     FORD|     7566|    JONES|           2|\n",
      "|     7788|    SCOTT|     7566|    JONES|           2|\n",
      "|     7499|    ALLEN|     7698|    BLAKE|           5|\n",
      "|     7521|     WARD|     7698|    BLAKE|           5|\n",
      "|     7654|   MARTIN|     7698|    BLAKE|           5|\n",
      "|     7844|   TURNER|     7698|    BLAKE|           5|\n",
      "|     7900|    JAMES|     7698|    BLAKE|           5|\n",
      "|     7934|   MILLER|     7782|    CLARK|           1|\n",
      "|     7876|    ADAMS|     7788|    SCOTT|           1|\n",
      "|     7698|    BLAKE|     7839|     KING|           3|\n",
      "|     7566|    JONES|     7839|     KING|           3|\n",
      "|     7782|    CLARK|     7839|     KING|           3|\n",
      "|     7369|    SMITH|     7902|     FORD|           1|\n",
      "+---------+---------+---------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resDf = spark.sql(\"\"\"\n",
    "                select \n",
    "                    a.empno as emp_empno,\n",
    "                    a.ename as emp_ename,\n",
    "                    b.empno as mgr_empno,\n",
    "                    b.ename as mgr_ename,\n",
    "                    c.emp_cnt as mgr_team_cnt\n",
    "                from emp a, emp b, (select \n",
    "                                    a.mgr, count(a.ename) as emp_cnt\n",
    "                                    from emp a, emp b\n",
    "                                    where a.mgr = b.empno\n",
    "                                    group by a.mgr) c\n",
    "                where a.mgr = b.empno\n",
    "                and b.empno = c.mgr\n",
    "                order by b.empno\n",
    "                \"\"\")\n",
    "resDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resDf.write.mode('overwrite').format('jdbc')\\\n",
    "    .option('url','jdbc:mysql://localhost:3306/saif_db?useSSL=False')\\\n",
    "    .option('user','root')\\\n",
    "    .option('password','root')\\\n",
    "    .option('driver','com.mysql.jdbc.Driver')\\\n",
    "    .option('dbtable','emp_mgr_cnt')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
